{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10daa93c-b24e-4c94-bf59-9fa5afcb527b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# 03_orchestration.py\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    when,\n",
    "    lit,\n",
    "    to_date,\n",
    "    concat_ws,\n",
    "    sum as _sum,\n",
    "    count,\n",
    "    max as _max\n",
    ")\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "\n",
    "def aggregate_by_client(risk_df):\n",
    "    aggr_df = (\n",
    "        risk_df.groupBy(\"client_id\")\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"total_transactions\"),\n",
    "            _sum(\"transaction_amount\").alias(\"total_amount\"),\n",
    "            _sum(when(col(\"risk_flag\"), 1).otherwise(0)).alias(\"high_risk_transactions\"),\n",
    "            _max(\"risk_score\").alias(\"max_risk_score\"),\n",
    "            _max(\"is_high_risk_country\").alias(\"ever_high_risk_country\"),\n",
    "            _max(\"is_minor\").alias(\"is_minor\")\n",
    "        )\n",
    "        .withColumn(\"high_risk_ratio\", col(\"high_risk_transactions\") / col(\"total_transactions\"))\n",
    "    )\n",
    "    return aggr_df\n",
    "\n",
    "def save_to_gold(aggr_df, gold_path):\n",
    "    (\n",
    "        aggr_df.write.format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(f\"{gold_path}/aggregated_client_risk\")\n",
    "    )\n",
    "\n",
    "# Parâmetros\n",
    "dbutils.widgets.text(\"silver_path\", \"/mnt/datalake/silver/kyc_risk_analysis\")\n",
    "dbutils.widgets.text(\"gold_path\", \"/mnt/datalake/gold/kyc_risk_analysis\")\n",
    "\n",
    "silver_path = dbutils.widgets.get(\"silver_path\")\n",
    "gold_path = dbutils.widgets.get(\"gold_path\")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"orchestration-kyc-risk\").getOrCreate()\n",
    "\n",
    "# Ler silver\n",
    "risk_df = spark.read.format(\"delta\").load(f\"{silver_path}/client_transactions_risk\")\n",
    "\n",
    "# Agregar\n",
    "aggr_df = aggregate_by_client(risk_df)\n",
    "\n",
    "# Salvar gold\n",
    "save_to_gold(aggr_df, gold_path)\n",
    "\n",
    "print(\"Agregação e gravação no Gold concluídas.\")\n",
    "\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# to display the silver table(client_transactions_risk)\n",
    "df_silver = spark.read.format(\"delta\").load(\"/mnt/datalake/silver/kyc_risk_analysis/client_transactions_risk\")\n",
    "df_silver.display()\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_processing_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

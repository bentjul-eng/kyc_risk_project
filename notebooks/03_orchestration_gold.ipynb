{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "10daa93c-b24e-4c94-bf59-9fa5afcb527b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2. Read bronze layer data\n",
    "bronze_path = \"dbfs:/Workspace/Users/jusoares_flor@hotmail.com/kyc_risk_project/data/csv_sources\"\n",
    "\n",
    "clients_df = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(f\"{bronze_path}/clients.csv\")\n",
    ")\n",
    "\n",
    "transactions_df = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(f\"{bronze_path}/transactions.csv\")\n",
    ")\n",
    "\n",
    "high_risk_countries_df = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(f\"{bronze_path}/high_risk_countries.csv\")\n",
    ")\n",
    "\n",
    "display(high_risk_countries_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "2fdfa828-5dad-4aca-9fc4-e31798dd00c1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#display(dbutils.fs.ls(\"dbfs:/Workspace/Users/jusoares_flor@hotmail.com/kyc_risk_project/data/csv_sources/high_risk_countries.csv\"))\n",
    "\n",
    "#dbutils.fs.rm(\"dbfs/Workspace/Users/jusoares_flor@hotmail.com/kyc_risk_project/data/csv_sources\", recurse=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7631f6cb-b6da-45d8-90ed-d9a160bd5dcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "joined_df = (\n",
    "    transactions_df.alias(\"t\")                               # transações\n",
    "    .join(clients_df.alias(\"c\"), on=\"client_id\", how=\"inner\") # + clientes\n",
    "    .join(                                                   # + países de risco\n",
    "        high_risk_countries_df.alias(\"h\")\n",
    "            .withColumnRenamed(\"country\", \"high_risk_country\"),\n",
    "        col(\"c.country\") == col(\"h.high_risk_country\"),\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .withColumn(\"is_high_risk_country\", col(\"h.high_risk_country\").isNotNull())\n",
    ")\n",
    "\n",
    "display(joined_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3b0bba98-3977-4269-a46e-f8910238d1b2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, when, lit, to_date, concat_ws\n",
    "\n",
    "# Calcular colunas de risco no DataFrame\n",
    "risk_df = joined_df \\\n",
    "    .withColumn(\n",
    "        \"is_high_value_transaction\",\n",
    "        when(col(\"transaction_amount\") > 10000, lit(1)).otherwise(lit(0))\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"is_minor\",\n",
    "        when(col(\"age\") < 18, lit(1)).otherwise(lit(0))\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"risk_score\",\n",
    "        col(\"is_high_risk_country\").cast(\"int\") * 1 +\n",
    "        col(\"is_high_value_transaction\").cast(\"int\") * 1.5 +\n",
    "        col(\"is_minor\").cast(\"int\") * 1\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"risk_flag\",\n",
    "        when(col(\"risk_score\") >= 2, lit(True)).otherwise(lit(False))\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"evaluation_timestamp\",\n",
    "        to_date(lit(\"2025-06-10\"))\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"event_id\",\n",
    "        concat_ws(col(\"client_id\"), col(\"transaction_id\"))\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "739a70b5-b5c0-4ce7-864c-f66e8270101c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "orchestration.py – KYC Risk Analysis project orchestration pipeline\n",
    "\"\"\"\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    when,\n",
    "    lit,\n",
    "    to_date,\n",
    "    concat_ws,\n",
    "    sum as _sum,\n",
    "    count,\n",
    "    max as _max\n",
    ")\n",
    "\n",
    "# -----------------------\n",
    "# General settings\n",
    "# -----------------------\n",
    "\n",
    "BRONZE_PATH = \"dbfs:/Workspace/Users/jusoares_flor@hotmail.com/kyc_risk_project/data/csv_sources\"\n",
    "SILVER_PATH = \"dbfs:/mnt/datalake/silver/kyc_risk_analysis\"\n",
    "GOLD_PATH = \"dbfs:/mnt/datalake/gold/kyc_risk_analysis\"\n",
    "EVALUATION_DATE = \"2025-06-10\"\n",
    "\n",
    "# -----------------------\n",
    "# auxiliary functions\n",
    "# -----------------------\n",
    "\n",
    "def load_raw():\n",
    "    \"\"\"Loads Bronze tier CSVs and returns PySpark DataFrames.\"\"\"\n",
    "    clients_df = (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(f\"{BRONZE_PATH}/clients.csv\")\n",
    "    )\n",
    "\n",
    "    transactions_df = (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(f\"{BRONZE_PATH}/transactions.csv\")\n",
    "    )\n",
    "\n",
    "    high_risk_countries_df = (\n",
    "        spark.read\n",
    "        .format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(f\"{BRONZE_PATH}/high_risk_countries.csv\")\n",
    "    )\n",
    "\n",
    "    return clients_df, transactions_df, high_risk_countries_df\n",
    "\n",
    "\n",
    "def enrich_risk(clients_df, transactions_df, high_risk_countries_df):\n",
    "    \"\"\"Enriches transactions with risk scores and KYC flags.\"\"\"\n",
    "\n",
    "    joined_df = (\n",
    "        transactions_df.alias(\"t\")\n",
    "        .join(clients_df.alias(\"c\"), on=\"client_id\", how=\"inner\")\n",
    "        .join(\n",
    "            high_risk_countries_df.alias(\"h\").withColumnRenamed(\"country\", \"high_risk_country\"),\n",
    "            col(\"c.country\") == col(\"h.high_risk_country\"),\n",
    "            how=\"left\",\n",
    "        )\n",
    "        .withColumn(\"is_high_risk_country\", col(\"h.high_risk_country\").isNotNull())\n",
    "    )\n",
    "\n",
    "    risk_df = (\n",
    "        joined_df\n",
    "        .withColumn(\n",
    "            \"is_high_value_transaction\",\n",
    "            when(col(\"transaction_amount\") > 10000, lit(1)).otherwise(lit(0)),\n",
    "        )\n",
    "        .withColumn(\"is_minor\", when(col(\"age\") < 18, lit(1)).otherwise(lit(0)))\n",
    "        .withColumn(\n",
    "            \"risk_score\",\n",
    "            col(\"is_high_risk_country\").cast(\"int\") * 1\n",
    "            + col(\"is_high_value_transaction\").cast(\"int\") * 1.5\n",
    "            + col(\"is_minor\").cast(\"int\") * 1,\n",
    "        )\n",
    "        .withColumn(\"risk_flag\", when(col(\"risk_score\") >= 2, lit(True)).otherwise(lit(False)))\n",
    "        .withColumn(\"evaluation_timestamp\", to_date(lit(EVALUATION_DATE)))\n",
    "        .withColumn(\"event_id\", concat_ws(\"_\", col(\"client_id\"), col(\"transaction_id\")))\n",
    "    )\n",
    "\n",
    "    return risk_df\n",
    "\n",
    "\n",
    "def save_to_silver(risk_df):\n",
    "    \"\"\"enriched DataFrame in Silver layer as Delta\"\"\"\n",
    "    (\n",
    "        risk_df.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(f\"{SILVER_PATH}/client_transactions_risk\")\n",
    "    )\n",
    "\n",
    "\n",
    "def aggregate_by_client(risk_df):\n",
    "\n",
    "    aggr_df = (\n",
    "        risk_df.groupBy(\"client_id\")\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"total_transactions\"),\n",
    "            _sum(\"transaction_amount\").alias(\"total_amount\"),\n",
    "            _sum(when(col(\"risk_flag\"), 1).otherwise(0)).alias(\"high_risk_transactions\"),\n",
    "            _max(\"risk_score\").alias(\"max_risk_score\"),\n",
    "            _max(\"is_high_risk_country\").alias(\"ever_high_risk_country\"),\n",
    "            _max(\"is_minor\").alias(\"is_minor\"),\n",
    "        )\n",
    "        .withColumn(\"high_risk_ratio\", col(\"high_risk_transactions\") / col(\"total_transactions\"))\n",
    "    )\n",
    "\n",
    "    return aggr_df\n",
    "\n",
    "\n",
    "def save_to_gold(aggr_df):\n",
    "    (\n",
    "        aggr_df.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(f\"{GOLD_PATH}/aggregated_client_risk\")\n",
    "    )\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# main orchestration\n",
    "# -----------------------\n",
    "\n",
    "def orchestrate():\n",
    "    clients_df, transactions_df, high_risk_countries_df = load_raw()\n",
    "    risk_df = enrich_risk(clients_df, transactions_df, high_risk_countries_df)\n",
    "\n",
    "    # Silver\n",
    "    save_to_silver(risk_df)\n",
    "\n",
    "    # Gold – aggregation\n",
    "    aggr_df = aggregate_by_client(risk_df)\n",
    "    save_to_gold(aggr_df)\n",
    "\n",
    "    return risk_df\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_orchestration_gold",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

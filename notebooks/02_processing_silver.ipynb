{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4dc49c9-e2d5-49b5-b7ea-2cf5918c72c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Databricks notebook source\n",
    "# 02_processing.py\n",
    "\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    when,\n",
    "    lit,\n",
    "    to_date,\n",
    "    concat_ws,\n",
    "    sum as _sum,\n",
    "    count,\n",
    "    max as _max\n",
    ")\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Utils functions (você pode importar de um módulo externo se preferir)\n",
    "def load_bronze_data(spark, bronze_path):\n",
    "    clients_df = (\n",
    "        spark.read.format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(f\"{bronze_path}/clients.csv\")\n",
    "    )\n",
    "    transactions_df = (\n",
    "        spark.read.format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(f\"{bronze_path}/transactions.csv\")\n",
    "    )\n",
    "    high_risk_countries_df = (\n",
    "        spark.read.format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .option(\"inferSchema\", \"true\")\n",
    "        .load(f\"{bronze_path}/high_risk_countries.csv\")\n",
    "    )\n",
    "    return clients_df, transactions_df, high_risk_countries_df\n",
    "\n",
    "def save_to_silver(df, silver_path):\n",
    "    (\n",
    "        df.write.format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .option(\"overwriteSchema\", \"true\")  # <- ESSA LINHA RESOLVE\n",
    "        .partitionBy(\"evaluation_date\")\n",
    "        .save(f\"{silver_path}/client_transactions_risk\")\n",
    "    )\n",
    "\n",
    "def enrich_risk(clients_df, transactions_df, high_risk_countries_df, evaluation_timestamp):\n",
    "    joined_df = (\n",
    "        transactions_df.alias(\"t\")\n",
    "        .join(clients_df.alias(\"c\"), on=\"client_id\", how=\"inner\")\n",
    "        .join(\n",
    "            high_risk_countries_df.alias(\"h\").withColumnRenamed(\"country\", \"high_risk_country\"),\n",
    "            col(\"c.country\") == col(\"h.high_risk_country\"),\n",
    "            how=\"left\"\n",
    "        )\n",
    "        .withColumn(\"is_high_risk_country\", col(\"h.high_risk_country\").isNotNull())\n",
    "    )\n",
    "\n",
    "    risk_df = (\n",
    "        joined_df\n",
    "        .withColumn(\"is_high_value_transaction\", when(col(\"transaction_amount\") > 10000, lit(1)).otherwise(lit(0)))\n",
    "        .withColumn(\"is_minor\", when(col(\"age\") < 18, lit(1)).otherwise(lit(0)))\n",
    "        .withColumn(\n",
    "            \"risk_score\",\n",
    "            col(\"is_high_risk_country\").cast(\"int\") * 1 +\n",
    "            col(\"is_high_value_transaction\").cast(\"int\") * 1.5 +\n",
    "            col(\"is_minor\").cast(\"int\") * 1\n",
    "        )\n",
    "        .withColumn(\"risk_flag\", when(col(\"risk_score\") >= 2, lit(True)).otherwise(lit(False)))\n",
    "        .withColumn(\"evaluation_timestamp\", lit(evaluation_timestamp).cast(\"timestamp\"))\n",
    "        .withColumn(\"evaluation_date\", to_date(col(\"evaluation_timestamp\")))\n",
    "        .withColumn(\"event_id\", concat_ws(\"_\", col(\"client_id\"), col(\"transaction_id\")))\n",
    "    )\n",
    "\n",
    "    return risk_df\n",
    "\n",
    "# Parâmetros\n",
    "dbutils.widgets.text(\"bronze_path\", \"/mnt/kycproject/raw_data\")\n",
    "dbutils.widgets.text(\"silver_path\", \"/mnt/datalake/silver/kyc_risk_analysis\")\n",
    "dbutils.widgets.text(\"evaluation_timestamp\", \"2025-06-10 12:00:00\")\n",
    "\n",
    "bronze_path = dbutils.widgets.get(\"bronze_path\")\n",
    "silver_path = dbutils.widgets.get(\"silver_path\")\n",
    "evaluation_timestamp = dbutils.widgets.get(\"evaluation_timestamp\")\n",
    "\n",
    "spark = SparkSession.builder.appName(\"processing-kyc-risk\").getOrCreate()\n",
    "\n",
    "# Carregar bronze\n",
    "clients_df, transactions_df, high_risk_countries_df = load_bronze_data(spark, bronze_path)\n",
    "\n",
    "# Enriquecer com risco\n",
    "risk_df = enrich_risk(clients_df, transactions_df, high_risk_countries_df, evaluation_timestamp)\n",
    "\n",
    "# Salvar silver\n",
    "save_to_silver(risk_df, silver_path)\n",
    "\n",
    "print(\"Processamento e gravação no Silver concluídos.\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_processing_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

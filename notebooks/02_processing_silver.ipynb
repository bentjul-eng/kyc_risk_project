{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e4dc49c9-e2d5-49b5-b7ea-2cf5918c72c0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import (\n",
    "    col,\n",
    "    when,\n",
    "    lit,\n",
    "    to_date,\n",
    "    concat_ws,\n",
    "    sum as _sum,\n",
    "    count,\n",
    "    max as _max\n",
    ")\n",
    "\n",
    "bronze_path = \"dbfs:/Workspace/Users/jusoares_flor@hotmail.com/kyc_risk_project/data/csv_sources\"\n",
    "silver_path = \"dbfs:/mnt/datalake/silver/kyc_risk_analysis\"\n",
    "gold_path = \"dbfs:/mnt/datalake/gold/kyc_risk_analysis\"\n",
    "evaluation_timestamp = \"2025-06-10 12:00:00\"\n",
    "\n",
    "\n",
    "bronze_path = \"dbfs:/Workspace/Users/jusoares_flor@hotmail.com/kyc_risk_project/data/csv_sources\"\n",
    "\n",
    "clients_df = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(f\"{bronze_path}/clients.csv\")\n",
    ")\n",
    "\n",
    "transactions_df = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(f\"{bronze_path}/transactions.csv\")\n",
    ")\n",
    "\n",
    "high_risk_countries_df = (\n",
    "    spark.read\n",
    "    .format(\"csv\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"inferSchema\", \"true\")\n",
    "    .load(f\"{bronze_path}/high_risk_countries.csv\")\n",
    ")\n",
    "\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "joined_df = (\n",
    "    transactions_df.alias(\"t\")                              \n",
    "    .join(clients_df.alias(\"c\"), on=\"client_id\", how=\"inner\") \n",
    "    .join(                                                  \n",
    "        high_risk_countries_df.alias(\"h\")\n",
    "            .withColumnRenamed(\"country\", \"high_risk_country\"),\n",
    "        col(\"c.country\") == col(\"h.high_risk_country\"),\n",
    "        how=\"left\"\n",
    "    )\n",
    "    .withColumn(\"is_high_risk_country\", col(\"h.high_risk_country\").isNotNull())\n",
    ")\n",
    "\n",
    "display(joined_df)\n",
    "\n",
    "\n",
    "from pyspark.sql.functions import col, when, lit, to_date, concat_ws\n",
    "\n",
    "# Calcular colunas de risco no DataFrame\n",
    "risk_df = joined_df \\\n",
    "    .withColumn(\n",
    "        \"is_high_value_transaction\",\n",
    "        when(col(\"transaction_amount\") > 10000, lit(1)).otherwise(lit(0))\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"is_minor\",\n",
    "        when(col(\"age\") < 18, lit(1)).otherwise(lit(0))\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"risk_score\",\n",
    "        col(\"is_high_risk_country\").cast(\"int\") * 1 +\n",
    "        col(\"is_high_value_transaction\").cast(\"int\") * 1.5 +\n",
    "        col(\"is_minor\").cast(\"int\") * 1\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"risk_flag\",\n",
    "        when(col(\"risk_score\") >= 2, lit(True)).otherwise(lit(False))\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"evaluation_timestamp\",\n",
    "        (lit(\"2025-06-10 12:00:00\").cast(\"timestamp\"))\n",
    "    ) \\\n",
    "    .withColumn(\n",
    "        \"evaluation_date\",\n",
    "        (to_date(col(\"evaluation_timestamp\")))\n",
    "    )\\\n",
    "    .withColumn(\n",
    "        \"event_id\",\n",
    "        concat_ws(col(\"client_id\"), col(\"transaction_id\"))\n",
    "    )\n",
    "\n",
    "display(risk_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c7b6e353-1e56-44a1-ba12-92dd49317452",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "(risk_df.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .partitionBy(\"evaluation_date\")\n",
    "        .save(f\"{silver_path}/client_transactions_risk\"))\n",
    "\n",
    "aggr_df = (\n",
    "        risk_df.groupBy(\"client_id\")\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"total_transactions\"),\n",
    "            _sum(\"transaction_amount\").alias(\"total_amount\"),\n",
    "            _sum(when(col(\"risk_flag\"), 1).otherwise(0)).alias(\"high_risk_transactions\"),\n",
    "            _max(\"risk_score\").alias(\"max_risk_score\"),\n",
    "            _max(\"is_high_risk_country\").alias(\"ever_high_risk_country\"),\n",
    "            _max(\"is_minor\").alias(\"is_minor\"),\n",
    "        )\n",
    "        .withColumn(\"high_risk_ratio\", col(\"high_risk_transactions\") / col(\"total_transactions\"))\n",
    "    )\n",
    "   \n",
    "display(aggr_df)\n",
    "\n",
    "(\n",
    "        aggr_df.write\n",
    "        .format(\"delta\")\n",
    "        .mode(\"overwrite\")\n",
    "        .save(f\"{gold_path}/aggregated_client_risk\")\n",
    "    )\n",
    "\n",
    "display(high_risk_countries_df)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_processing_silver",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
